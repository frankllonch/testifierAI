[
  {
    "question": "En scikit-learn, ¿qué función devuelve matriz de confusión tras predecir?",
    "options": [
      "confusion_matrix(y_true, y_pred)",
      "classification_report(y_true, y_pred)",
      "accuracy_score(y_true, y_pred)",
      "roc_auc_score(y_true, y_score)"
    ],
    "correct": 0,
    "explanation": "La función confusion_matrix de sklearn.metrics recibe etiquetas verdaderas y predichas y calcula la matriz de confusión."
  },
  {
    "question": "¿Cómo se fija la semilla aleatoria en train_test_split?",
    "options": [
      "train_test_split(..., random_state=42)",
      "train_test_split(..., shuffle=False)",
      "train_test_split(..., seed=42)",
      "train_test_split(..., rng=42)"
    ],
    "correct": 0,
    "explanation": "El parámetro random_state fija la semilla interna para reproducir la partición de los datos."
  },
  {
    "question": "En un Pipeline de sklearn, ¿cómo accedes al mejor parámetro tras GridSearchCV?",
    "options": [
      "grid.best_params_",
      "grid.best_estimator_",
      "grid.cv_results_",
      "grid.best_score_"
    ],
    "correct": 0,
    "explanation": "best_params_ es un diccionario con la combinación de hiperparámetros que obtuvo mejor rendimiento."
  },
  {
    "question": "¿Qué método de un objeto PCA permite transformar datos originales?",
    "options": [
      "pca.transform(X)",
      "pca.fit(X)",
      "pca.predict(X)",
      "pca.score(X)"
    ],
    "correct": 0,
    "explanation": "Después de ajustar con pca.fit, transform aplica la proyección a las nuevas muestras."
  },
  {
    "question": "Para guardar un modelo entrenado con joblib, ¿qué función usas?",
    "options": [
      "joblib.dump(model, 'file.pkl')",
      "joblib.load('file.pkl')",
      "pickle.dumps(model)",
      "model.save('file.pkl')"
    ],
    "correct": 0,
    "explanation": "joblib.dump serializa el objeto model en un archivo .pkl para su posterior recarga."
  },
  {
    "question": "¿Qué función crea un vectorizador de texto que cuenta ocurrencias?",
    "options": [
      "CountVectorizer()",
      "TfidfVectorizer()",
      "HashingVectorizer()",
      "DictVectorizer()"
    ],
    "correct": 0,
    "explanation": "CountVectorizer de sklearn.feature_extraction convierte documentos en matrices de conteos de tokens."
  },
  {
    "question": "¿Cómo obtienes coeficientes de un modelo lineal ajustado en sklearn?",
    "options": [
      "model.coef_",
      "model.weights_",
      "model.parameters_",
      "model.coefs_"
    ],
    "correct": 0,
    "explanation": "coef_ es un array con los pesos (coeficientes) de las variables predictoras."
  },
  {
    "question": "¿Qué método de sklearn.metrics calcula puntuación F1 promedio en multiclass?",
    "options": [
      "f1_score(y_true, y_pred, average='macro')",
      "f1_score(y_true, y_pred)",
      "precision_score(y_true, y_pred)",
      "recall_score(y_true, y_pred)"
    ],
    "correct": 0,
    "explanation": "average='macro' calcula F1 por clase y luego su media aritmética, ignorando desequilibrios."
  },
  {
    "question": "Para aplicar escalado antes de PCA en un Pipeline, ¿qué paso añades?",
    "options": [
      "('scale', StandardScaler())",
      "('pca', PCA())",
      "('clf', LogisticRegression())",
      "('cv', KFold())"
    ],
    "correct": 0,
    "explanation": "Se suele estandarizar con StandardScaler antes de PCA para centrar y escalar variables."
  },
  {
    "question": "¿Cómo se calcula el AUC para un clasificador binario en sklearn?",
    "options": [
      "roc_auc_score(y_true, y_score)",
      "auc(fpr, tpr)",
      "roc_curve(y_true, y_score)",
      "precision_recall_curve(y_true, y_score)"
    ],
    "correct": 0,
    "explanation": "roc_auc_score recibe etiquetas verdaderas y puntuaciones de probabilidad para calcular AUC."
  },
  {
    "question": "¿Qué objeto de sklearn almacena resultados completos de validación cruzada?",
    "options": [
      "GridSearchCV(cv_results_)",
      "cross_val_score",
      "train_test_split",
      "StratifiedKFold"
    ],
    "correct": 0,
    "explanation": "cv_results_ es un diccionario con puntuaciones, parámetros y tiempos de cada combinación probada."
  },
  {
    "question": "¿En qué formato devuelve cross_val_score sus puntuaciones?",
    "options": [
      "Arreglo de floats para cada fold",
      "Diccionario con métricas",
      "DataFrame con resultados",
      "Objeto ScoreResult"
    ],
    "correct": 0,
    "explanation": "cross_val_score devuelve una lista o array con la puntuación obtenida en cada partición."
  },
  {
    "question": "¿Qué parámetro define número de vecinos en KNeighborsClassifier?",
    "options": [
      "n_neighbors=5",
      "n_estimators=5",
      "max_depth=5",
      "n_clusters=5"
    ],
    "correct": 0,
    "explanation": "n_neighbors especifica cuántos puntos vecinos se consideran para la predicción."
  },
  {
    "question": "¿Cómo configuras un árbol de decisión para no sobreajustar?",
    "options": [
      "max_depth=5",
      "min_samples_split=2",
      "criterion='gini'",
      "splitter='best'"
    ],
    "correct": 0,
    "explanation": "Limitar la profundidad máxima reduce la complejidad y combate el sobreajuste."
  },
  {
    "question": "¿Qué método evalúa la puntuación en un conjunto de prueba?",
    "options": [
      "model.score(X_test, y_test)",
      "model.predict(X_test)",
      "model.fit(X_test)",
      "model.transform(X_test)"
    ],
    "correct": 0,
    "explanation": "score calcula la métrica por defecto (accuracy en clasificadores) sobre los datos de prueba."
  },
  {
    "question": "¿Qué retorna train_test_split cuando pides dos arrays?",
    "options": [
      "X_train, X_test, y_train, y_test",
      "X_train, y_train",
      "X_test, y_test",
      "X_full, y_full"
    ],
    "correct": 0,
    "explanation": "train_test_split separa simultáneamente características y etiquetas en entrenamiento y prueba."
  },
  {
    "question": "¿Cómo conviertes DataFrame con variables categóricas a dummies?",
    "options": [
      "pd.get_dummies(df)",
      "df.fillna(0)",
      "df.dropna()",
      "df.scale()"
    ],
    "correct": 0,
    "explanation": "get_dummies crea columnas binarias para cada nivel de las variables categóricas."
  },
  {
    "question": "¿Qué evalúa permutation_importance tras entrenar modelo?",
    "options": [
      "Importancia de característica tras permutaciones",
      "Precisión del modelo entrenado",
      "Número de iteraciones hasta converger",
      "Tamaño del modelo serializado"
    ],
    "correct": 0,
    "explanation": "Permutation_importance mide caída en la métrica al permutar cada característica."
  },
  {
    "question": "¿Qué función ofrece el módulo joblib para paralelizar?",
    "options": [
      "Parallel(n_jobs=4)",
      "GridSearchCV(n_jobs=4)",
      "KFold(n_jobs=4)",
      "PCA(n_jobs=4)"
    ],
    "correct": 0,
    "explanation": "Parallel de joblib permite ejecutar loops en paralelo aprovechando múltiples núcleos."
  },
  {
    "question": "¿Cómo compruebas si un Pipeline contiene StandardScaler?",
    "options": [
      "('scale' in pipe.named_steps)",
      "hasattr(pipe, 'scale')",
      "pipe.steps[0]",
      "pipe.containsScaler()"
    ],
    "correct": 0,
    "explanation": "named_steps es un diccionario con las tuplas de nombre y transformador del Pipeline."
  }
]