[
  {
    "question": "¿Qué mide el Error Cuadrático Medio (MSE) en un modelo de regresión?",
    "options": [
      "La media de los errores absolutos sin elevar",
      "La media de los cuadrados de los residuos",
      "La suma de desviaciones absolutas sobre el promedio",
      "La magnitud cuadrática promedio de todos los errores"
    ],
    "correct": 1,
    "explanation": "MSE = (1/N)·∑(yi−ŷi)²; promedia los cuadrados de las diferencias entre valores reales y predichos."
  },
  {
    "question": "¿En qué difiere el Error Absoluto Medio (MAE) respecto al MSE?",
    "options": [
      "MAE penaliza más los errores grandes sin elevar",
      "MAE usa diferencias absolutas en lugar de cuadrados",
      "MAE promedia los valores absolutos de los errores",
      "MAE enfatiza errores pequeños sobre errores grandes ocasionales"
    ],
    "correct": 1,
    "explanation": "MAE = (1/N)·∑|yi−ŷi|; promedia las magnitudes de los errores sin elevarlos al cuadrado."
  },
  {
    "question": "¿Qué indica el coeficiente de determinación R²?",
    "options": [
      "Porcentaje de varianza total explicado por modelo",
      "Proporción de varianza explicada por el modelo",
      "Media de diferencias entre valores y predicciones",
      "Nivel de correlación entre variable y predicción"
    ],
    "correct": 1,
    "explanation": "R² = 1−(SSres/SStot); muestra qué fracción de la varianza de los datos explica el modelo."
  },
  {
    "question": "¿Para qué sirve la estadística F en regresión?",
    "options": [
      "Detectar heterocedasticidad en los residuos",
      "Medir dependencia serial en residuos",
      "Evaluar significancia global del modelo",
      "Analizar colinealidad entre variables predictoras"
    ],
    "correct": 2,
    "explanation": "F compara varianza explicada por el modelo frente a la no explicada; un F alto indica modelo significativo."
  },
  {
    "question": "¿Qué informa el valor p asociado a un coeficiente β?",
    "options": [
      "Magnitud del efecto estimado sobre la variable",
      "Probabilidad de observar el coeficiente bajo H₀",
      "Variabilidad del coeficiente bajo la hipótesis nula",
      "Grado de asociación estadística entre variables explicativas"
    ],
    "correct": 1,
    "explanation": "El p–value mide qué tan probable es obtener ese β si en realidad efectividad fuese cero (hipótesis nula)."
  },
  {
    "question": "¿Qué mide la estadística Durbin–Watson?",
    "options": [
      "Autocorrelación de residuos",
      "Distribución de residuos",
      "Asimetría en residuos",
      "Observaciones atípicas totales"
    ],
    "correct": 0,
    "explanation": "Durbin–Watson detecta correlación serial en residuos; un valor cercano a 2 indica independencia."
  },
  {
    "question": "¿Cuál es el propósito de la prueba Jarque–Bera?",
    "options": [
      "Evaluar heterocedasticidad de los residuos",
      "Testear normalidad de los residuos",
      "Medir dependencia serial en regresión",
      "Analizar asimetría y curtosis conjunta"
    ],
    "correct": 1,
    "explanation": "Jarque–Bera combina asimetría y curtosis de residuos para verificar si siguen una distribución normal."
  },
  {
    "question": "¿Qué describe el criterio de información de Akaike (AIC)?",
    "options": [
      "Error de predicción en validación",
      "Comparación de modelos penalizando complejidad",
      "Proporción de varianza explicada global",
      "Número óptimo de variables predictoras"
    ],
    "correct": 1,
    "explanation": "AIC = 2k−2·ln(L); equilibra bondad de ajuste (verosimilitud L) y número de parámetros k."
  },
  {
    "question": "¿Qué mide la curtosis (kurtosis) de los residuos?",
    "options": [
      "Grado de asimetría en la distribución estadística",
      "Peso de las colas de la distribución",
      "Anchura de la curva normal estándar distribución",
      "Número de picos en la distribución observada"
    ],
    "correct": 1,
    "explanation": "La curtosis evalúa si hay más valores extremos (colas pesadas) o menos (colas ligeras) que en una normal."
  },
  {
    "question": "¿Qué identifica la estadística Omnibus en regresión?",
    "options": [
      "Evaluar linealidad del modelo",
      "Significancia individual de β",
      "Normalidad conjunta de residuos",
      "Detectar heterocedasticidad en residuos"
    ],
    "correct": 2,
    "explanation": "El test Omnibus combina asimetría y curtosis para evaluar normalidad global de los residuos."
  },
  {
    "question": "¿Cuál es la diferencia entre Label Encoding y One-Hot Encoding?",
    "options": [
      "Label codifica categorías; One-Hot genera múltiples columnas",
      "Label asigna enteros; One-Hot crea columnas binarias",
      "Ambos métodos crean vectores de representación binaria",
      "Label reduce dimensionalidad; One-Hot mantiene unicidad categorías"
    ],
    "correct": 1,
    "explanation": "LabelEncoder mapea categorías a enteros, One-Hot genera una columna por categoría evitando orden implícito."
  },
  {
    "question": "¿Cuál es el objetivo de la regresión lineal múltiple?",
    "options": [
      "Clasificar instancias en categorías predefinidas basándose en etiquetas previamente",
      "Predecir una variable continua en función de varias independientes",
      "Agrupar datos similares usando algoritmos sin etiquetas externas previas",
      "Reducir dimensiones de datos manteniendo máxima información relevante estadística"
    ],
    "correct": 1,
    "explanation": "La regresión múltiple modela y estima un valor numérico basado en varias variables predictoras."
  },
  {
    "question": "¿Qué asunción exige homocedasticidad en regresión?",
    "options": [
      "Residuos con varianza constante",
      "Residuos independientes entre sí",
      "Residuos con distribución normal",
      "Predictores libres de multicolinealidad"
    ],
    "correct": 0,
    "explanation": "Homocedasticidad implica que la varianza de residuos es la misma para todos los niveles de predictores."
  },
  {
    "question": "¿Por qué es importante la independencia de errores?",
    "options": [
      "Evita sobreajuste en entrenamiento",
      "Permite inferencias estadísticas válidas",
      "Reduce dimensión de datos",
      "Mejora velocidad de cálculo"
    ],
    "correct": 1,
    "explanation": "La autocorrelación en residuos viola supuestos, afectando validez de pruebas t y F."
  },
  {
    "question": "¿Qué problema indica un Cond. No. muy alto?",
    "options": [
      "Outliers en Y",
      "Colinealidad entre predictores",
      "Error de especificación",
      "Insuficiente muestra disponible"
    ],
    "correct": 1,
    "explanation": "El número de condición evalúa sensibilidad de XᵀX; un valor alto señala multicolinealidad."
  },
  {
    "question": "¿Qué transformaciones permiten linealizar modelos exponenciales?",
    "options": [
      "Logaritmo en Y y/o X",
      "Raíz cuadrada en Y solamente",
      "Elevar datos a potencia arbitraria",
      "Normalizar variables mediante escala min-max"
    ],
    "correct": 0,
    "explanation": "ln(Y)=ln(a)+bX convierte relaciones exponenciales en forma lineal para aplicar regresión lineal."
  },
  {
    "question": "¿Cuál es la ventaja de la regresión Ridge?",
    "options": [
      "Elimina variables irrelevantes del modelo predictivo",
      "Penaliza coeficientes grandes para reducir varianza",
      "No requiere estandarizar previamente las variables",
      "Maximiza varianza explicada sin penalización alguna"
    ],
    "correct": 1,
    "explanation": "Ridge (L2) añade α·∑βj² al costo, evitando coeficientes extremos y mejorando generalización."
  },
  {
    "question": "¿Qué característica distingue a Lasso frente a Ridge?",
    "options": [
      "Lasso usa penalización L1 generando sparsity",
      "Lasso solo reduce coeficientes sin eliminarlos",
      "Lasso no requiere parámetro alfa definido",
      "Lasso es exclusivo para problemas clasificación"
    ],
    "correct": 0,
    "explanation": "Lasso (L1) puede forzar algunos coeficientes a cero, realizando selección implícita de variables."
  },
  {
    "question": "¿En qué caso usarías Elastic Net?",
    "options": [
      "Cuando se desea combinar L1 y L2 para equilibrio entre sparsity y estabilidad estadística",
      "Cuando existen fuertes multicolinealidades en variables predictoras y se necesita regularización implícita estadística",
      "Para mejorar interpretabilidad de coeficientes sin eliminar totalmente variables en modelos lineales simples",
      "Cuando se busca equilibrio entre bias y variance en algoritmos regulares estadísticos complejos"
    ],
    "correct": 0,
    "explanation": "Elastic Net mezcla penalizaciones L1 y L2; útil si hay multicolinealidad y se desea selección de variables."
  },
  {
    "question": "¿Qué distingue la regresión logística binaria de la multiclase?",
    "options": [
      "Binaria predice dos clases; multiclase más de dos",
      "Binaria utiliza MSE como métrica; multiclase usa MAE",
      "No existe diferencia matemática significativa entre ellas ambas",
      "Multiclase aplica función softmax en lugar de sigmoide"
    ],
    "correct": 0,
    "explanation": "La logística binaria modela P(y=1), la multinomial extiende a K categorías mutuamente excluyentes."
  },
  {
    "question": "¿Cuál es el propósito de la función sigmoide en regresión logística?",
    "options": [
      "Generar un valor continuo no acotado sin límite interpretativo posible",
      "Transformar la combinación lineal en una probabilidad entre 0 y 1",
      "Linealizar relaciones no lineales curvas para análisis y visualización efectiva adicional",
      "Reducir dimensionalidad conservando información significativa para análisis predictivo estadístico robusto complejo"
    ],
    "correct": 1,
    "explanation": "σ(z)=1/(1+e⁻ᶻ) convierte la salida lineal en un valor acotado [0,1] interpretable como probabilidad."
  },
  {
    "question": "¿Qué métrica es común para evaluar regresores basados en árboles?",
    "options": [
      "AUC-ROC y PR-AUC sobre datos binarios",
      "MSE o MAE sobre datos de prueba",
      "Recall y F1-score sobre datos de validación",
      "Silhouette score usado en clustering unsupervised analysis"
    ],
    "correct": 1,
    "explanation": "Para regresión se usan MSE, MAE o R² en conjunto de validación."
  },
  {
    "question": "¿Qué ventaja principal tiene Random Forest en regresión?",
    "options": [
      "Entrenamiento muy rápido con gran paralelización interna automática",
      "Mejora estabilidad y reduce varianza promediando muchos árboles",
      "Elimina totalmente colinealidad en predictores de forma implícita",
      "Garantiza interpretabilidad completa de cada árbol usado internamente"
    ],
    "correct": 1,
    "explanation": "Forest promedia predicciones de múltiples árboles entrenados en subconjuntos aleatorios, reduciendo overfitting."
  },
  {
    "question": "¿Para qué sirve el parámetro learning_rate en Gradient Boosting?",
    "options": [
      "Determinar máxima profundidad permitida para cada árbol individual entrenado",
      "Controlar cuánto corrige cada nuevo árbol el error residual",
      "Número mínimo de muestras requeridas en cada hoja terminal",
      "Cantidad exacta de árboles a entrenar en el modelo"
    ],
    "correct": 1,
    "explanation": "learning_rate escala la contribución de cada árbol en el ensemble para evitar ajustes demasiado agresivos."
  },
  {
    "question": "¿Qué describe la curva de aprendizaje (learning curve)?",
    "options": [
      "Evolución del error de entrenamiento y validación según tamaño de datos",
      "Cambio de múltiples hiperparámetros y su efecto en error predictivo modelado",
      "Variación del criterio de información Akaike AIC según alpha paramétrico modelístico",
      "Distribución de residuos de entrenamiento y validación en gráfica comparativa estadística"
    ],
    "correct": 0,
    "explanation": "Las learning curves muestran cómo se reduce error en entrenamiento y validación al aumentar datos o complejidad."
  },
  {
    "question": "¿Por qué se realiza la validación cruzada k-fold?",
    "options": [
      "Para estimar rendimiento estable usando k particiones",
      "Para usar todo el dataset como entrenamiento",
      "Para aumentar el tamaño conjunto de prueba",
      "Para normalizar variables antes del modelado estadístico"
    ],
    "correct": 0,
    "explanation": "Cross-validation divide datos en k bloques, entrenando k veces con distintos folds para evaluar robustez del modelo."
  },
  {
    "question": "¿Qué indica un alto sesgo (bias) en el bias-variance tradeoff?",
    "options": [
      "Modelo muy complejo (overfitting)",
      "Modelo demasiado simple (underfitting)",
      "Modelo con muchos datos",
      "Modelo con alta varianza"
    ],
    "correct": 1,
    "explanation": "Un bias alto implica que el modelo no capta patrones complejos y rinde pobre tanto en entrenamiento como en prueba."
  },
  {
    "question": "¿Qué indica una alta varianza en el bias-variance tradeoff?",
    "options": [
      "Overfitting",
      "Underfitting",
      "Heterocedasticidad",
      "Multicolinealidad"
    ],
    "correct": 0,
    "explanation": "Alta varianza significa que el modelo se ajusta demasiado al ruido de entrenamiento y no generaliza bien."
  },
  {
    "question": "¿Cuál es el objetivo final al ajustar hiperparámetros?",
    "options": [
      "Maximizar el ajuste al conjunto completo de entrenamiento inicial primario",
      "Minimizar todos los errores registrados en entrenamiento inicial primario",
      "Encontrar equilibrio que maximice rendimiento en datos no vistos",
      "Eliminar todas las variables irrelevantes del modelo final estadístico"
    ],
    "correct": 2,
    "explanation": "La optimización de hiperparámetros busca mejorar la generalización, no solo el desempeño en entrenamiento."
  }
]