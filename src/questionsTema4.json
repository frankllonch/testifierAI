[
  {
    "question": "¿Qué describe mejor una red neuronal artificial?",
    "options": [
      "Un conjunto de nodos conectados que imitan neuronas reales",
      "Una estructura de datos para representar relaciones complejas",
      "Un algoritmo de búsqueda para optimizar rutas en grafos",
      "Una red de comunicaciones para transmitir datos continuamente"
    ],
    "correct": 0,
    "explanation": "Una red neuronal usa nodos y conexiones ponderadas para aprender patrones complejos de datos mediante entrenamiento iterativo."
  },
  {
    "question": "¿Cuál es la función principal de la capa de entrada?",
    "options": [
      "Recibir datos crudos y prepararlos para las capas ocultas",
      "Regular dinámicamente la tasa de aprendizaje del modelo",
      "Eliminar ruido y limpiar los datos de entrada bruta",
      "Aplicar regularización temprana antes del entrenamiento completo"
    ],
    "correct": 0,
    "explanation": "La capa de entrada recibe las características originales, opcionalmente las normaliza y las envía a las capas posteriores para procesar."
  },
  {
    "question": "¿Para qué sirven las capas ocultas en una red?",
    "options": [
      "Extraer características intermedias y aprender relaciones no lineales",
      "Sincronizar entrenamientos en múltiples GPUs simultáneamente",
      "Presentar el resultado final directamente al usuario final",
      "Calcular métricas internas de rendimiento para la red"
    ],
    "correct": 0,
    "explanation": "Las capas ocultas transforman información usando activaciones no lineales, aprendiendo representaciones intermedias útiles para la predicción."
  },
  {
    "question": "¿Qué ventaja tiene usar ReLU en redes profundas?",
    "options": [
      "Mantiene gradiente positivo y simplifica el cálculo de activaciones",
      "Restringe siempre las salidas entre cero y uno fijas",
      "Es completamente suave y diferenciable en todos los puntos",
      "Proporciona salidas simétricas en rangos negativo y positivo"
    ],
    "correct": 0,
    "explanation": "ReLU activa solo valores positivos, acelerando el entrenamiento y mitigando el problema de gradientes que desaparecen en redes profundas."
  },
  {
    "question": "¿En qué difiere un Perceptrón de ADALINE?",
    "options": [
      "Perceptrón usa escalón y ADALINE minimiza error cuadrático medio",
      "Ambos usan la misma función de activación escalón idéntica",
      "ADALINE emplea función escalón no diferenciable estricta",
      "Perceptrón minimiza directamente el error cuadrático medio"
    ],
    "correct": 0,
    "explanation": "El perceptrón actualiza pesos solo si hay error de clasificación, mientras ADALINE ajusta continuamente para minimizar el error MSE."
  },
  {
    "question": "¿Qué garantiza el teorema de convergencia del perceptrón?",
    "options": [
      "Encontrar una separación si los datos son linealmente separables",
      "Converger siempre independientemente de la distribución de datos",
      "No converger si existen clases muy desbalanceadas internamente",
      "Mejorar automáticamente la tasa de aprendizaje adaptativa"
    ],
    "correct": 0,
    "explanation": "Si existe un hiperplano separador, el algoritmo del perceptrón lo encontrará en un número finito de iteraciones asegurando convergencia."
  },
  {
    "question": "¿Qué ocurre durante la propagación hacia adelante?",
    "options": [
      "Se calculan las salidas de cada capa con pesos y activaciones",
      "Se actualizan los pesos del modelo usando gradiente descendente",
      "Los datos se fragmentan en lotes aleatorios para entrenamiento",
      "Se normalizan nuevamente los datos antes de cada capa"
    ],
    "correct": 0,
    "explanation": "En forward propagation cada capa aplica sus pesos y función de activación para generar salidas que alimentan la siguiente capa."
  },
  {
    "question": "¿Cuál es el propósito de la retropropagación (backpropagation)?",
    "options": [
      "Calcular gradientes y actualizar pesos para minimizar la función de pérdida",
      "Separar automáticamente conjuntos de validación y prueba del modelo",
      "Incrementar la tasa de aprendizaje de manera dinámica continua",
      "Eliminar neuronas inactivas para simplificar la arquitectura interna"
    ],
    "correct": 0,
    "explanation": "Backpropagation calcula cómo cada peso afecta la pérdida, usa esos gradientes para ajustar pesos en dirección contraria al gradiente."
  },
  {
    "question": "¿Qué define una epoch en el entrenamiento de redes?",
    "options": [
      "Una pasada completa por todo el conjunto de datos de entrenamiento",
      "Cada actualización individual de un peso específico interno",
      "Cada batch de muestras procesado de forma independiente separada",
      "La primera evaluación del modelo en el conjunto de prueba"
    ],
    "correct": 0,
    "explanation": "Una epoch ocurre cuando el modelo procesa todas las muestras de entrenamiento una vez, marcando un ciclo completo de aprendizaje."
  },
  {
    "question": "¿Para qué sirve Dropout en redes neuronales?",
    "options": [
      "Reducir sobreajuste desconectando aleatoriamente neuronas durante entrenamiento",
      "Aumentar arbitrariamente la profundidad total de la red neuronal",
      "Normalizar automáticamente las salidas al rango de cero a uno",
      "Acelerar el cálculo de gradientes en unidades de GPU"
    ],
    "correct": 0,
    "explanation": "Dropout evita coadaptación apagando aleatoriamente un porcentaje de neuronas en cada iteración, mejorando robustez y generalización."
  },
  {
    "question": "¿Cuál es el rol de Softmax en la capa de salida?",
    "options": [
      "Convertir logits en probabilidades normales que suman exactamente uno",
      "Introducir una no linealidad suave en capas intermedias ocultas",
      "Normalizar características de entrada antes del procesamiento interno",
      "Aumentar drásticamente la profundidad de la arquitectura de red"
    ],
    "correct": 0,
    "explanation": "Softmax transforma los valores de salida (logits) en una distribución de probabilidad que suma uno para clasificación multiclase."
  },
  {
    "question": "¿Qué hace Early Stopping durante el aprendizaje?",
    "options": [
      "Detener el entrenamiento cuando la métrica de validación deja de mejorar",
      "Aumentar progresivamente la tasa de aprendizaje con cada epoch",
      "Duplicar el tamaño del lote de entrenamiento en cada ciclo",
      "Eliminar automáticamente capas ocultas viejas tras iteraciones"
    ],
    "correct": 0,
    "explanation": "Early Stopping detiene el entrenamiento si la métrica de validación no mejora durante varias epochs, evitando sobreajuste del modelo."
  },
  {
    "question": "¿Qué mide el Error Cuadrático Medio (MSE)?",
    "options": [
      "El promedio de los errores al cuadrado entre predicciones y valores reales",
      "La proporción total de aciertos en tareas de clasificación binarias",
      "La velocidad de convergencia del optimizador en cada iteración",
      "La dimensionalidad efectiva de las características de entrada usadas"
    ],
    "correct": 0,
    "explanation": "MSE calcula la media de los errores al cuadrado, penalizando errores grandes y ofreciendo una métrica diferenciable para optimizar."
  },
  {
    "question": "¿Qué evalúa la entropía cruzada binaria?",
    "options": [
      "La disimilitud entre dos distribuciones de probabilidad en clasificación binaria",
      "La distancia euclídea absoluta entre vectores de características usados",
      "La proporción de varianza explicada por componentes principales",
      "La tasa de aciertos media en clasificación multicapa compleja"
    ],
    "correct": 0,
    "explanation": "La entropía cruzada cuantifica el error en las predicciones probabilísticas, penalizando predicciones confiadas y equivocadas en binaria."
  },
  {
    "question": "¿Cómo diferencian L1 y L2 regularización?",
    "options": [
      "L1 induce esparsidad anulando coeficientes; L2 reduce magnitudes sin cero",
      "L1 adapta internamente la tasa de aprendizaje; L2 regula el tamaño del lote",
      "No existe diferencia en cómo penalizan los pesos entrenables",
      "L1 es exclusivo de RNN; L2 solo para redes convolucionales profundas"
    ],
    "correct": 0,
    "explanation": "L1 penaliza la suma de valores absolutos generando esparsidad, mientras L2 penaliza la suma de cuadrados reduciendo magnitudes sin anular."
  },
  {
    "question": "¿Qué rol tiene el bias en una neurona?",
    "options": [
      "Un término adicional entrenable que desplaza la salida de la activación",
      "La tasa fija de aprendizaje inicial usada en todo el entrenamiento",
      "El tamaño predeterminado del lote utilizado durante el entrenamiento",
      "El nodo de salida principal de la capa anterior procesada"
    ],
    "correct": 0,
    "explanation": "El bias ajusta la función de activación independientemente de las entradas, permitiendo que la neurona modele umbrales más flexibles."
  },
  {
    "question": "¿Cuál es el objetivo del descenso de gradiente?",
    "options": [
      "Minimizar la función de pérdida actualizando pesos en dirección opuesta al gradiente",
      "Maximizar la tasa de aprendizaje utilizando un esquema adaptativo interno",
      "Eliminar por completo el ruido presente en los datos de entrada",
      "Dividir automáticamente los datos en varios lotes para entrenamiento"
    ],
    "correct": 0,
    "explanation": "El descenso de gradiente ajusta los pesos iterativamente en la dirección contraria al gradiente de la pérdida para reducir el error."
  },
  {
    "question": "¿Qué define una red profunda (DNN)?",
    "options": [
      "Varias capas ocultas secuenciales que extraen características jerárquicas complejas",
      "Solo una única capa oculta capaz de procesar toda la tarea",
      "Ausencia total de funciones de activación en capas ocultas internas",
      "Incapacidad de entrenarse mediante retropropagación tradicional"
    ],
    "correct": 0,
    "explanation": "Una DNN tiene múltiples capas ocultas que permiten aprender representaciones cada vez más abstractas y complejas de los datos."
  },
  {
    "question": "¿Qué ventaja aporta la activación Swish?",
    "options": [
      "Suavidad continua que combina linealidad y no linealidad mejorando convergencia",
      "Generar únicamente resultados binarios estrictos de cero o uno constantes",
      "Funcionamiento idéntico a ReLU sin ninguna diferencia práctica",
      "Saturación rápida que limita salidas tanto para valores grandes como pequeños"
    ],
    "correct": 0,
    "explanation": "Swish es suave y diferenciable en todo el dominio, manteniendo gradientes incluso para valores negativos y mejorando rendimiento."
  },
  {
    "question": "¿Qué beneficio ofrece Softplus sobre ReLU?",
    "options": [
      "suavidad diferenciable en todo el rango evitando discontinuidades de gradiente",
      "Generar siempre salidas binarias de cero y uno exactos",
      "Activar únicamente entradas positivas de gran magnitud internamente",
      "Saturar completamente para todos los valores negativos procesados"
    ],
    "correct": 0,
    "explanation": "Softplus es una versión suave de ReLU, evitando discontinuidades en el gradiente y mejorando la estabilidad del entrenamiento profundo."
  },
  {
    "question": "¿Cómo describirías la arquitectura CNN?",
    "options": [
      "Capas de convolución que extraen patrones locales espaciales en datos",
      "Perceptrón multicapa simple sin uso de convoluciones internas",
      "Red recurrente diseñada para procesar secuencias temporales",
      "Módulo de atención que no emplea filtros convolucionales"
    ],
    "correct": 0,
    "explanation": "Las CNN utilizan filtros deslizantes para capturar patrones locales en imágenes o datos estructurados espacialmente, reduciendo parámetros."
  },
  {
    "question": "¿Para qué se usan principalmente las RNN?",
    "options": [
      "Modelar secuencias y dependencias temporales en datos secuenciales",
      "Clasificar imágenes independientes sin orden temporal preciso",
      "Realizar clustering jerárquico en datos completamente estáticos",
      "Ejecutar transformaciones lineales simples en cada capa"
    ],
    "correct": 0,
    "explanation": "Las RNN mantienen un estado interno que captura contextos previos, siendo ideales para texto, series temporales y otras secuencias."
  },
  {
    "question": "¿Qué produce la capa de salida en un modelo?",
    "options": [
      "La predicción final según la tarea de clasificación o regresión deseada",
      "Un almacenamiento temporal de todos los pesos internos ajustados",
      "La eliminación de características irrelevantes del modelo entrenado",
      "Un aumento automático del tamaño del lote utilizado"
    ],
    "correct": 0,
    "explanation": "La capa de salida genera los valores finales (probabilidades o predicciones continuas) listos para evaluación o uso posterior."
  },
  {
    "question": "¿Qué define una GAN en aprendizaje profundo?",
    "options": [
      "Arquitectura con dos redes en competencia generador y discriminador",
      "Perceptrón simple de una sola capa sin competencia interna",
      "Red neuronal sin función de pérdida definida externamente",
      "Modelo de clustering jerárquico sin componente generativo"
    ],
    "correct": 0,
    "explanation": "Las GAN consisten en un generador y un discriminador que compiten, mejorando la calidad de muestras sintéticas generadas."
  },
  {
    "question": "¿Qué describe el tradeoff sesgo-varianza?",
    "options": [
      "Equilibrio entre sesgo y varianza para lograr buena generalización",
      "Diferencia principal entre aprendizaje supervisado y no supervisado",
      "Relación entre tasa de aprendizaje y tamaño del lote",
      "Funcionamiento interno del optimizador Adam adaptativo"
    ],
    "correct": 0,
    "explanation": "El tradeoff busca un modelo ni demasiado simple (alto sesgo) ni demasiado complejo (alta varianza) para maximizar generalización."
  },
  {
    "question": "¿Qué mide la función de pérdida en entrenamiento?",
    "options": [
      "El error cuantitativo medio entre predicciones y valores reales dados",
      "La profundidad efectiva de la red neuronal utilizada internamente",
      "El número total de parámetros ajustables entrenados internamente",
      "La tasa adaptativa de aprendizaje usada durante la optimización"
    ],
    "correct": 0,
    "explanation": "La función de pérdida cuantifica el desajuste entre predicciones y realidad, guiando el proceso de optimización hacia mejores soluciones."
  },
  {
    "question": "¿Qué problema soluciona Batch Normalization?",
    "options": [
      "Estabilizar y acelerar el entrenamiento normalizando activaciones de cada lote",
      "Eliminar completamente el sobreajuste en todos los casos",
      "Incrementar automáticamente la tasa de aprendizaje adaptativa",
      "Reducir drásticamente el tamaño final del modelo entrenado"
    ],
    "correct": 0,
    "explanation": "Batch Normalization normaliza activaciones dentro de cada batch, reduciendo covariate shift y acelerando entrenamiento de redes profundas."
  },
  {
    "question": "¿Por qué inicializar correctamente los pesos?",
    "options": [
      "Evita saturación de activaciones y acelera la convergencia del entrenamiento",
      "Garantiza precisión perfecta en todos los escenarios posibles",
      "Permite usar cualquier valor de tasa de aprendizaje sin ajuste",
      "Reduce automáticamente la cantidad de capas necesarias"
    ],
    "correct": 0,
    "explanation": "Una buena inicialización previene activaciones muertas o explosivas, facilitando el flujo de gradientes y mejorando la convergencia."
  },
  {
    "question": "¿Qué hace un scheduler de tasa de aprendizaje?",
    "options": [
      "Adaptar la tasa durante el entrenamiento para mejorar la convergencia general",
      "Mantener constante la tasa inicial durante todo el proceso",
      "Evitar la selección de funciones de activación en la red",
      "Eliminar por completo la necesidad de ajustar hiperparámetros"
    ],
    "correct": 0,
    "explanation": "Un scheduler ajusta dinámicamente el learning rate según el progreso de entrenamiento, evitando estancamientos y mejorando estabilidad."
  }
]