[
    {
      "question": "¿Cuál es el objetivo principal del Análisis de Componentes Principales (PCA)?",
      "options": [
        "Reducir la dimensionalidad manteniendo la mayor parte de la varianza",
        "Aumentar el número de variables",
        "Normalizar los datos a escala 0–1",
        "Construir clusters jerárquicos"
      ],
      "correct": 0,
      "explanation": "PCA busca representar los datos originales con menos variables (componentes) sin perder información significativa de varianza.  [oai_citation:0‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué paso es imprescindible antes de aplicar PCA?",
      "options": [
        "Estandarizar las variables a media 0 y varianza 1",
        "Ejecutar K-Means",
        "Calcular lift",
        "Realizar downsampling"
      ],
      "correct": 0,
      "explanation": "La estandarización evita que variables con escalas muy diferentes dominen los componentes principales.  [oai_citation:1‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué matriz se descompone en PCA para extraer los componentes?",
      "options": [
        "Matriz de covarianza o de correlación",
        "Matriz de confusión",
        "Matriz de adyacencia",
        "Matriz de distancias"
      ],
      "correct": 0,
      "explanation": "Se utiliza la matriz de covarianza (o correlación) de los datos estandarizados para hallar autovalores y autovectores.  [oai_citation:2‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se eligen los componentes principales en PCA?",
      "options": [
        "Ordenando autovalores de mayor a menor y seleccionando los primeros",
        "Por orden alfabético de variables",
        "Según la media de cada variable",
        "Aleatoriamente"
      ],
      "correct": 0,
      "explanation": "Se retienen los componentes asociados a los autovalores más grandes, que explican mayor varianza.  [oai_citation:3‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Para qué sirve el Scree Plot en PCA?",
      "options": [
        "Ayudar a decidir cuántos componentes retener",
        "Medir la densidad de clusters",
        "Calcular soporte en Apriori",
        "Ajustar hiperparámetros de DBSCAN"
      ],
      "correct": 0,
      "explanation": "El Scree Plot muestra la varianza explicada por cada componente, indicando un codo donde cortar.  [oai_citation:4‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué describe la transformación de datos tras PCA?",
      "options": [
        "Proyección de los datos originales sobre el espacio de componentes",
        "Clustering de los datos",
        "Normalización a 0–1",
        "Selección de variables irrelevantes"
      ],
      "correct": 0,
      "explanation": "Se multiplican los datos por los autovectores para obtener coordenadas en el espacio reducido.  [oai_citation:5‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cuál es el objetivo del algoritmo K-Means?",
      "options": [
        "Minimizar la varianza intra-cluster",
        "Maximizar la entropía",
        "Reducir dimensionalidad",
        "Encontrar reglas de asociación"
      ],
      "correct": 0,
      "explanation": "K-Means busca agrupar datos minimizando la suma de distancias al cuadrado al centroide de cada clúster.  [oai_citation:6‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se inicializan los centroides en K-Means?",
      "options": [
        "Seleccionando k puntos aleatorios de los datos",
        "Usando PCA",
        "Con reglas de asociación",
        "Con gradiente descendente"
      ],
      "correct": 0,
      "explanation": "Se eligen k muestras iniciales al azar (o con k-means++ para mejor convergencia).  [oai_citation:7‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se asignan los puntos a un clúster en K-Means?",
      "options": [
        "Calculando la distancia euclídea a cada centroide",
        "Por similitud de texto",
        "Mediante reglas de asociación",
        "Con Q-Learning"
      ],
      "correct": 0,
      "explanation": "Cada punto se asigna al clúster cuyo centroide esté más cercano según distancia euclídea.  [oai_citation:8‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se actualizan los centroides en K-Means?",
      "options": [
        "Calculando la media de los puntos asignados a cada clúster",
        "Usando la mediana de los puntos",
        "Aplicando PCA",
        "Con backpropagation"
      ],
      "correct": 0,
      "explanation": "El nuevo centroide es el promedio de todas las observaciones asignadas al clúster.  [oai_citation:9‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cuál es el criterio de convergencia en K-Means?",
      "options": [
        "Cuando los centroides dejan de cambiar significativamente",
        "Cuando se alcanza un número de clusters fijo",
        "Cuando la entropía es cero",
        "Cuando aumenta la dimensionalidad"
      ],
      "correct": 0,
      "explanation": "Se detiene al estabilizarse los centroides o al llegar al máximo de iteraciones.  [oai_citation:10‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué mide la inercia (WCSS) en K-Means?",
      "options": [
        "Suma de distancias al cuadrado de puntos a sus centroides",
        "Número de clusters",
        "Varianza total del conjunto",
        "Densidad de puntos"
      ],
      "correct": 0,
      "explanation": "WCSS cuantifica la dispersión interna de cada clúster, menor inercia indica clusters más compactos.  [oai_citation:11‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Para qué sirve el coeficiente de silueta?",
      "options": [
        "Evaluar la calidad de los clusters según cohesión y separación",
        "Medir la varianza explicada en PCA",
        "Calcular soporte en Apriori",
        "Determinar eps en DBSCAN"
      ],
      "correct": 0,
      "explanation": "La silueta compara la distancia media intracluster con la distancia media al cluster vecino más cercano.  [oai_citation:12‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué aporta el índice de Davies-Bouldin?",
      "options": [
        "Medida de separación entre clusters; valores bajos indican mejor definición",
        "Recuento de puntos ruido",
        "Longitud de las iteraciones",
        "Nivel de overfitting"
      ],
      "correct": 0,
      "explanation": "Evalúa relación entre dispersión de clusters y distancia entre sus centroides; menor valores mejor.  [oai_citation:13‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿En qué consiste el método del codo (elbow method)?",
      "options": [
        "Analizar la curva de WCSS vs k para encontrar un punto de inflexión",
        "Aplicar PCA al conjunto de clusters",
        "Usar silueta para elegir k",
        "Minimizar entropía"
      ],
      "correct": 0,
      "explanation": "Se grafica inercia según número de clusters y se elige k donde la mejora se atenúa (codo).  [oai_citation:14‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué idea central sustenta DBSCAN?",
      "options": [
        "Agrupar en función de la densidad de puntos en el espacio de características",
        "Minimizar WCSS",
        "Reducir dimensionalidad",
        "Generar reglas de asociación"
      ],
      "correct": 0,
      "explanation": "DBSCAN forma clusters conectando regiones densas separadas por regiones de baja densidad.  [oai_citation:15‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué define un punto núcleo en DBSCAN?",
      "options": [
        "Un punto con al menos min_samples en su vecindario eps",
        "Un punto aislado",
        "Un centroide en K-Means",
        "Un punto con baja densidad"
      ],
      "correct": 0,
      "explanation": "Los puntos núcleo tienen suficientes vecinos dentro de eps para formar un cluster.  [oai_citation:16‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué es un punto frontera en DBSCAN?",
      "options": [
        "No cumple min_samples pero está dentro de eps de un núcleo",
        "Un ruido",
        "Un nuevo cluster",
        "Un centroide"
      ],
      "correct": 0,
      "explanation": "Los puntos frontera no son núcleos pero se asignan a clusters existentes si están cerca de un nodo núcleo.  [oai_citation:17‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se clasifica un punto ruido en DBSCAN?",
      "options": [
        "Ni núcleo ni frontera, se excluye de clusters",
        "Se asigna a un cluster",
        "Se convierte en centroide",
        "Se etiqueta como outlier"
      ],
      "correct": 0,
      "explanation": "Los puntos ruido no tienen suficientes vecinos y quedan fuera de cualquier clúster.  [oai_citation:18‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué parámetros son esenciales en DBSCAN?",
      "options": [
        "eps y min_samples",
        "k y max_iter",
        "n_components y whiten",
        "support y confidence"
      ],
      "correct": 0,
      "explanation": "eps define el radio de vecindad y min_samples el número mínimo de puntos para formar un núcleo.  [oai_citation:19‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cuál es el propósito del algoritmo Apriori?",
      "options": [
        "Descubrir patrones de asociación frecuentes en transacciones",
        "Reducir dimensionalidad",
        "Agrupar datos por densidad",
        "Entrenar redes neuronales"
      ],
      "correct": 0,
      "explanation": "Apriori identifica ítems frecuentes y genera reglas de asociación basándose en soporte y confianza.  [oai_citation:20‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se define el soporte (support) de un ítem o conjunto?",
      "options": [
        "Proporción de transacciones que contienen el ítem",
        "Número de reglas generadas",
        "Distancia al cuadrado al centroide",
        "Varianza explicada"
      ],
      "correct": 0,
      "explanation": "Support mide la frecuencia relativa de aparición de un ítem en las transacciones totales.  [oai_citation:21‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué representa la confianza (confidence) en una regla X → Y?",
      "options": [
        "Proporción de transacciones con X que también contienen Y",
        "Proporción de transacciones con Y",
        "Número de clústeres",
        "Tamaño del cluster más grande"
      ],
      "correct": 0,
      "explanation": "Confidence evalúa cuán probable es observar Y dado que X ya está presente en la transacción.  [oai_citation:22‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se interpreta el lift de una regla X → Y?",
      "options": [
        "Indica dependencia positiva (>1), independiente (=1) o negativa (<1)",
        "Mide la densidad de clusters",
        "Calcula la varianza explicada",
        "Define el número de clusters óptimo"
      ],
      "correct": 0,
      "explanation": "Lift compara la frecuencia conjunta con la esperada si X e Y fueran independientes.  [oai_citation:23‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué caracteriza al aprendizaje por refuerzo?",
      "options": [
        "Un agente aprende a través de interacciones y recompensas en un entorno",
        "Aprendizaje supervisado con etiquetas",
        "Clustering no supervisado",
        "Regresión lineal"
      ],
      "correct": 0,
      "explanation": "En RL el agente toma acciones, observa recompensas y ajusta su política para maximizar recompensa acumulada.  [oai_citation:24‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué representa la actualización Q(s,a) en Q-Learning?",
      "options": [
        "Ajuste del valor Q combinando recompensa inmediata y valor futuro máximo",
        "Cálculo de la derivada de la función de pérdida",
        "Selección de centroides",
        "Cálculo de soporte y confianza"
      ],
      "correct": 0,
      "explanation": "La fórmula Q ← (1-α)Q + α[r + γ·max Q] actualiza la estimación de valor acción-estado.  [oai_citation:25‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Qué papel juega el factor de descuento γ en Q-Learning?",
      "options": [
        "Valorar recompensas futuras respecto a las inmediatas",
        "Controlar la exploración",
        "Ajustar el tamaño del batch",
        "Definir el número de clusters"
      ],
      "correct": 0,
      "explanation": "γ (0–1) pondera la importancia de recompensas futuras: valores cercanos a 1 priorizan recompensas a largo plazo.  [oai_citation:26‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Para qué se usa la estrategia ε-greedy en RL?",
      "options": [
        "Equilibrar exploración (aleatoria) y explotación (mejor acción conocida)",
        "Normalizar estados",
        "Actualizar parámetros de K-Means",
        "Calcular soporte"
      ],
      "correct": 0,
      "explanation": "ε-greedy selecciona la mejor acción con probabilidad 1-ε y explora acciones aleatorias con probabilidad ε.  [oai_citation:27‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    },
    {
      "question": "¿Cómo se evalúa el rendimiento en aprendizaje por refuerzo?",
      "options": [
        "Recompensa acumulada promedio por episodio",
        "Precisión y recall",
        "Coeficiente de silueta",
        "Lift"
      ],
      "correct": 0,
      "explanation": "Se mide la recompensa total obtenida por episodio para valorar la calidad de la política aprendida.  [oai_citation:28‡Tema_05.pdf](file-service://file-Md9sNVmK4GcvdEhnzLKexm)"
    }
  ]